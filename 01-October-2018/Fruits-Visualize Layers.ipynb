{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing.image import save_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the datset. \n",
    "### The orginal dataset can be downloaded from https://github.com/Horea94/Fruit-Images-Dataset\n",
    "### Reference: Horea Muresan, Mihai Oltean, Fruit recognition from images using deep learning, Acta Univ. Sapientiae, Informatica Vol. 10, Issue 1, pp. 26-42, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/l1525goi53teden/fruits-360.zip?dl=0\n",
    "!mv fruits-360.zip\\?dl\\=0 fruits-360.zip\n",
    "!unzip fruits-360.zip\n",
    "!rm fruits-360.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = './train/'\n",
    "validation_data_dir = './valid/'\n",
    "nb_train_samples = 31688\n",
    "nb_validation_samples = 10657\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33125 images belonging to 81 classes.\n",
      "Found 8197 images belonging to 81 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to to split train data folder into train and validation is given below.\n",
    "### This is useful when you just have two folders for Train and Test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_datagen = ImageDataGenerator(\n",
    "#     rescale=1. / 255,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     validation_split=0.2)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = total_datagen.flow_from_directory(\n",
    "#     train_data_dir,\n",
    "#     target_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     subset=\"training\")\n",
    "\n",
    "# validation_generator = total_datagen.flow_from_directory(\n",
    "#     validation_data_dir,\n",
    "#     target_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#      subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ResNet50 Model for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "inception_base = applications.ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We load the pre-trained ResNet50 network from disk. Do notice how we have\n",
    "### included the parameter include_top=False – supplying this value indicates \n",
    "### that the final fully- connected layers should not be included in the architecture. \n",
    "### Therefore, when forward propagating an image through the network, we’ll obtain the\n",
    "### feature values after the final POOL layer rather than the probabilities produced by \n",
    "### the softmax classifier in the FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inception_base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(81, activation='softmax')(x)\n",
    "inception_transfer = Model(inputs=inception_base.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_transfer.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 81)           41553       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,678,353\n",
      "Trainable params: 24,625,233\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_transfer.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=33125 // 64,\n",
    "    epochs=5, shuffle = True, verbose = 1, \n",
    "    max_queue_size=10,\n",
    "    validation_data=validation_generator,\n",
    "\tvalidation_steps=8197 // 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the Network see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = inception_transfer.input\n",
    "layer_dict = dict([(layer.name, layer) for layer in inception_transfer.layers[1:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'res5b_branch2a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter 0\n",
      "Current loss value: -1.8854146\n",
      "Filter 0 processed in 4s\n",
      "Processing filter 1\n",
      "Current loss value: -0.3695934\n",
      "Filter 1 processed in 2s\n",
      "Processing filter 2\n",
      "Current loss value: -0.54007083\n",
      "Filter 2 processed in 3s\n",
      "Processing filter 3\n",
      "Current loss value: -1.092056\n",
      "Filter 3 processed in 3s\n",
      "Processing filter 4\n",
      "Current loss value: 0.45698902\n",
      "Current loss value: 1.2760646\n",
      "Current loss value: 2.3000803\n",
      "Current loss value: 3.2999067\n",
      "Current loss value: 4.3154783\n",
      "Current loss value: 4.864712\n",
      "Current loss value: 5.586628\n",
      "Current loss value: 6.071331\n",
      "Current loss value: 6.840914\n",
      "Current loss value: 7.493054\n",
      "Current loss value: 8.102612\n",
      "Current loss value: 8.67634\n",
      "Current loss value: 9.129922\n",
      "Current loss value: 9.755965\n",
      "Current loss value: 10.142498\n",
      "Current loss value: 10.8106\n",
      "Current loss value: 11.057241\n",
      "Current loss value: 11.730542\n",
      "Current loss value: 11.846345\n",
      "Current loss value: 12.382079\n",
      "Filter 4 processed in 5s\n",
      "Processing filter 5\n",
      "Current loss value: -0.026552707\n",
      "Filter 5 processed in 3s\n",
      "Processing filter 6\n",
      "Current loss value: -0.76596355\n",
      "Filter 6 processed in 3s\n",
      "Processing filter 7\n",
      "Current loss value: -0.48856658\n",
      "Filter 7 processed in 3s\n",
      "Processing filter 8\n",
      "Current loss value: -1.9268092\n",
      "Filter 8 processed in 3s\n",
      "Processing filter 9\n",
      "Current loss value: -0.542965\n",
      "Filter 9 processed in 3s\n",
      "Processing filter 10\n",
      "Current loss value: -0.82148963\n",
      "Filter 10 processed in 3s\n",
      "Processing filter 11\n",
      "Current loss value: -0.3933711\n",
      "Filter 11 processed in 4s\n",
      "Processing filter 12\n",
      "Current loss value: -1.3453149\n",
      "Filter 12 processed in 3s\n",
      "Processing filter 13\n",
      "Current loss value: -0.10187447\n",
      "Filter 13 processed in 3s\n",
      "Processing filter 14\n",
      "Current loss value: -1.5265712\n",
      "Filter 14 processed in 4s\n",
      "Processing filter 15\n",
      "Current loss value: -1.2836611\n",
      "Filter 15 processed in 4s\n",
      "Processing filter 16\n",
      "Current loss value: -2.781763\n",
      "Filter 16 processed in 4s\n",
      "Processing filter 17\n",
      "Current loss value: -1.1197928\n",
      "Filter 17 processed in 4s\n",
      "Processing filter 18\n",
      "Current loss value: -0.32941416\n",
      "Filter 18 processed in 4s\n",
      "Processing filter 19\n",
      "Current loss value: 0.056239337\n",
      "Current loss value: 0.84960514\n",
      "Current loss value: 1.4327453\n",
      "Current loss value: 2.3994558\n",
      "Current loss value: 2.982068\n",
      "Current loss value: 3.7603188\n",
      "Current loss value: 4.2397923\n",
      "Current loss value: 4.679389\n",
      "Current loss value: 4.975355\n",
      "Current loss value: 5.5957313\n",
      "Current loss value: 6.147522\n",
      "Current loss value: 6.500616\n",
      "Current loss value: 6.6108522\n",
      "Current loss value: 7.2606277\n",
      "Current loss value: 7.262846\n",
      "Current loss value: 7.8640237\n",
      "Current loss value: 8.12354\n",
      "Current loss value: 8.385438\n",
      "Current loss value: 9.086845\n",
      "Current loss value: 9.030316\n",
      "Filter 19 processed in 6s\n",
      "Processing filter 20\n",
      "Current loss value: -0.52321625\n",
      "Filter 20 processed in 4s\n",
      "Processing filter 21\n",
      "Current loss value: -0.46419215\n",
      "Filter 21 processed in 4s\n",
      "Processing filter 22\n",
      "Current loss value: -1.2606465\n",
      "Filter 22 processed in 5s\n",
      "Processing filter 23\n",
      "Current loss value: -2.0751188\n",
      "Filter 23 processed in 4s\n",
      "Processing filter 24\n",
      "Current loss value: -0.3885171\n",
      "Filter 24 processed in 5s\n",
      "Processing filter 25\n",
      "Current loss value: -1.7560551\n",
      "Filter 25 processed in 5s\n",
      "Processing filter 26\n",
      "Current loss value: -0.16968957\n",
      "Filter 26 processed in 5s\n",
      "Processing filter 27\n",
      "Current loss value: -0.91171026\n",
      "Filter 27 processed in 5s\n",
      "Processing filter 28\n",
      "Current loss value: -0.9574915\n",
      "Filter 28 processed in 5s\n",
      "Processing filter 29\n",
      "Current loss value: 0.78823733\n",
      "Current loss value: 1.7414587\n",
      "Current loss value: 2.255838\n",
      "Current loss value: 2.4824302\n",
      "Current loss value: 3.0474565\n",
      "Current loss value: 3.6252086\n",
      "Current loss value: 4.004982\n",
      "Current loss value: 4.369179\n",
      "Current loss value: 4.469958\n",
      "Current loss value: 5.2093143\n",
      "Current loss value: 5.166543\n",
      "Current loss value: 5.9028134\n",
      "Current loss value: 5.9708333\n",
      "Current loss value: 6.3642907\n",
      "Current loss value: 6.5129027\n",
      "Current loss value: 6.922982\n",
      "Current loss value: 7.205293\n",
      "Current loss value: 7.2036505\n",
      "Current loss value: 7.898438\n",
      "Current loss value: 8.052062\n",
      "Filter 29 processed in 8s\n",
      "Processing filter 30\n",
      "Current loss value: -0.41444093\n",
      "Filter 30 processed in 5s\n",
      "Processing filter 31\n",
      "Current loss value: 0.041313365\n",
      "Current loss value: 0.86577266\n",
      "Current loss value: 1.928458\n",
      "Current loss value: 2.7476115\n",
      "Current loss value: 3.4549243\n",
      "Current loss value: 4.4580135\n",
      "Current loss value: 4.3864217\n",
      "Current loss value: 5.071006\n",
      "Current loss value: 4.9207945\n",
      "Current loss value: 5.6791763\n",
      "Current loss value: 6.047443\n",
      "Current loss value: 6.286352\n",
      "Current loss value: 5.8813114\n",
      "Current loss value: 6.7158613\n",
      "Current loss value: 6.928359\n",
      "Current loss value: 7.331069\n",
      "Current loss value: 7.557394\n",
      "Current loss value: 7.920772\n",
      "Current loss value: 8.302764\n",
      "Current loss value: 8.78729\n",
      "Filter 31 processed in 7s\n",
      "Processing filter 32\n",
      "Current loss value: 0.57314587\n",
      "Current loss value: 1.4132615\n",
      "Current loss value: 2.792799\n",
      "Current loss value: 4.492819\n",
      "Current loss value: 5.9573846\n",
      "Current loss value: 6.7004557\n",
      "Current loss value: 7.306775\n",
      "Current loss value: 7.911224\n",
      "Current loss value: 8.6852665\n",
      "Current loss value: 9.353478\n",
      "Current loss value: 9.976884\n",
      "Current loss value: 10.358199\n",
      "Current loss value: 10.831296\n",
      "Current loss value: 11.105767\n",
      "Current loss value: 11.532284\n",
      "Current loss value: 11.8820915\n",
      "Current loss value: 12.502455\n",
      "Current loss value: 12.7723875\n",
      "Current loss value: 13.167095\n",
      "Current loss value: 13.450615\n",
      "Filter 32 processed in 8s\n",
      "Processing filter 33\n",
      "Current loss value: -1.4854026\n",
      "Filter 33 processed in 6s\n",
      "Processing filter 34\n",
      "Current loss value: -0.3161693\n",
      "Filter 34 processed in 6s\n",
      "Processing filter 35\n",
      "Current loss value: -0.34769037\n",
      "Filter 35 processed in 6s\n",
      "Processing filter 36\n",
      "Current loss value: -1.7071873\n",
      "Filter 36 processed in 6s\n",
      "Processing filter 37\n",
      "Current loss value: -0.73846763\n",
      "Filter 37 processed in 6s\n",
      "Processing filter 38\n",
      "Current loss value: -1.02344\n",
      "Filter 38 processed in 6s\n",
      "Processing filter 39\n",
      "Current loss value: -0.3744261\n",
      "Filter 39 processed in 7s\n",
      "Processing filter 40\n",
      "Current loss value: 0.054000396\n",
      "Current loss value: 0.8636881\n",
      "Current loss value: 2.0924437\n",
      "Current loss value: 2.4925783\n",
      "Current loss value: 3.42812\n",
      "Current loss value: 3.9673593\n",
      "Current loss value: 4.505922\n",
      "Current loss value: 5.3073764\n",
      "Current loss value: 5.5392094\n",
      "Current loss value: 6.1175413\n",
      "Current loss value: 6.2620125\n",
      "Current loss value: 7.0593715\n",
      "Current loss value: 7.1229486\n",
      "Current loss value: 7.902374\n",
      "Current loss value: 7.823344\n",
      "Current loss value: 8.583314\n",
      "Current loss value: 8.478667\n",
      "Current loss value: 9.273862\n",
      "Current loss value: 9.107146\n",
      "Current loss value: 9.620161\n",
      "Filter 40 processed in 9s\n",
      "Processing filter 41\n",
      "Current loss value: -0.8149364\n",
      "Filter 41 processed in 7s\n",
      "Processing filter 42\n",
      "Current loss value: 0.10141891\n",
      "Current loss value: 1.032165\n",
      "Current loss value: 1.7497506\n",
      "Current loss value: 2.2351213\n",
      "Current loss value: 3.0916216\n",
      "Current loss value: 3.865861\n",
      "Current loss value: 4.5570216\n",
      "Current loss value: 4.686941\n",
      "Current loss value: 5.368318\n",
      "Current loss value: 6.152082\n",
      "Current loss value: 6.396196\n",
      "Current loss value: 7.0382504\n",
      "Current loss value: 7.5360317\n",
      "Current loss value: 7.5355897\n",
      "Current loss value: 8.334876\n",
      "Current loss value: 8.477097\n",
      "Current loss value: 8.890585\n",
      "Current loss value: 9.477658\n",
      "Current loss value: 9.530465\n",
      "Current loss value: 9.860114\n",
      "Filter 42 processed in 9s\n",
      "Processing filter 43\n",
      "Current loss value: -0.21433435\n",
      "Filter 43 processed in 7s\n",
      "Processing filter 44\n",
      "Current loss value: -1.4877053\n",
      "Filter 44 processed in 7s\n",
      "Processing filter 45\n",
      "Current loss value: 0.5926667\n",
      "Current loss value: 1.4373759\n",
      "Current loss value: 2.35148\n",
      "Current loss value: 3.0595813\n",
      "Current loss value: 3.561506\n",
      "Current loss value: 3.8552206\n",
      "Current loss value: 4.5341897\n",
      "Current loss value: 5.069776\n",
      "Current loss value: 5.5040126\n",
      "Current loss value: 6.0669675\n",
      "Current loss value: 6.1458917\n",
      "Current loss value: 6.4924355\n",
      "Current loss value: 6.990258\n",
      "Current loss value: 7.0229106\n",
      "Current loss value: 7.494688\n",
      "Current loss value: 7.683244\n",
      "Current loss value: 7.945681\n",
      "Current loss value: 8.26787\n",
      "Current loss value: 8.382173\n",
      "Current loss value: 8.622574\n",
      "Filter 45 processed in 9s\n",
      "Processing filter 46\n",
      "Current loss value: 0.15747237\n",
      "Current loss value: 1.0732774\n",
      "Current loss value: 2.1162345\n",
      "Current loss value: 2.8773642\n",
      "Current loss value: 3.4328108\n",
      "Current loss value: 4.2538815\n",
      "Current loss value: 4.841501\n",
      "Current loss value: 5.391881\n",
      "Current loss value: 5.807387\n",
      "Current loss value: 6.3656883\n",
      "Current loss value: 6.6543903\n",
      "Current loss value: 7.328326\n",
      "Current loss value: 7.57276\n",
      "Current loss value: 8.14277\n",
      "Current loss value: 8.71922\n",
      "Current loss value: 8.918684\n",
      "Current loss value: 9.311295\n",
      "Current loss value: 9.680424\n",
      "Current loss value: 9.840601\n",
      "Current loss value: 10.221203\n",
      "Filter 46 processed in 9s\n",
      "Processing filter 47\n",
      "Current loss value: -0.6793367\n",
      "Filter 47 processed in 8s\n",
      "Processing filter 48\n",
      "Current loss value: -1.3925253\n",
      "Filter 48 processed in 8s\n",
      "Processing filter 49\n",
      "Current loss value: -0.79755545\n",
      "Filter 49 processed in 8s\n",
      "Processing filter 50\n",
      "Current loss value: -0.88564324\n",
      "Filter 50 processed in 8s\n",
      "Processing filter 51\n",
      "Current loss value: -0.7463689\n",
      "Filter 51 processed in 9s\n",
      "Processing filter 52\n",
      "Current loss value: -0.041991904\n",
      "Filter 52 processed in 9s\n",
      "Processing filter 53\n",
      "Current loss value: -1.9128524\n",
      "Filter 53 processed in 9s\n",
      "Processing filter 54\n",
      "Current loss value: -0.45519865\n",
      "Filter 54 processed in 9s\n",
      "Processing filter 55\n",
      "Current loss value: -0.31921366\n",
      "Filter 55 processed in 9s\n",
      "Processing filter 56\n",
      "Current loss value: -1.3510085\n",
      "Filter 56 processed in 9s\n",
      "Processing filter 57\n",
      "Current loss value: -0.90074366\n",
      "Filter 57 processed in 9s\n",
      "Processing filter 58\n",
      "Current loss value: -0.5207778\n",
      "Filter 58 processed in 10s\n",
      "Processing filter 59\n",
      "Current loss value: -2.3457692\n",
      "Filter 59 processed in 10s\n",
      "Processing filter 60\n",
      "Current loss value: 0.09937462\n",
      "Current loss value: 0.9382901\n",
      "Current loss value: 1.4037856\n",
      "Current loss value: 1.908878\n",
      "Current loss value: 2.1755886\n",
      "Current loss value: 2.638493\n",
      "Current loss value: 2.9220524\n",
      "Current loss value: 3.090208\n",
      "Current loss value: 3.330542\n",
      "Current loss value: 3.5717638\n",
      "Current loss value: 3.6062243\n",
      "Current loss value: 4.21664\n",
      "Current loss value: 4.0946164\n",
      "Current loss value: 4.6684976\n",
      "Current loss value: 4.7443748\n",
      "Current loss value: 5.107516\n",
      "Current loss value: 5.012356\n",
      "Current loss value: 5.5541844\n",
      "Current loss value: 5.9419694\n",
      "Current loss value: 5.977303\n",
      "Filter 60 processed in 12s\n",
      "Processing filter 61\n",
      "Current loss value: -0.49075645\n",
      "Filter 61 processed in 10s\n",
      "Processing filter 62\n",
      "Current loss value: -1.1471047\n",
      "Filter 62 processed in 10s\n",
      "Processing filter 63\n",
      "Current loss value: -1.3275148\n",
      "Filter 63 processed in 10s\n",
      "Processing filter 64\n",
      "Current loss value: -2.3913457\n",
      "Filter 64 processed in 11s\n",
      "Processing filter 65\n",
      "Current loss value: -1.2714641\n",
      "Filter 65 processed in 12s\n",
      "Processing filter 66\n",
      "Current loss value: -0.3198431\n",
      "Filter 66 processed in 11s\n",
      "Processing filter 67\n",
      "Current loss value: -1.3320932\n",
      "Filter 67 processed in 11s\n",
      "Processing filter 68\n",
      "Current loss value: -1.4764049\n",
      "Filter 68 processed in 11s\n",
      "Processing filter 69\n",
      "Current loss value: 0.012992197\n",
      "Current loss value: 0.6917227\n",
      "Current loss value: 1.5511122\n",
      "Current loss value: 2.179486\n",
      "Current loss value: 2.806109\n",
      "Current loss value: 3.1801035\n",
      "Current loss value: 3.7476926\n",
      "Current loss value: 4.473697\n",
      "Current loss value: 4.6854634\n",
      "Current loss value: 5.454433\n",
      "Current loss value: 5.749574\n",
      "Current loss value: 6.0121346\n",
      "Current loss value: 6.4425983\n",
      "Current loss value: 6.955503\n",
      "Current loss value: 7.269104\n",
      "Current loss value: 7.2826614\n",
      "Current loss value: 7.8385186\n",
      "Current loss value: 7.6991987\n",
      "Current loss value: 8.676368\n",
      "Current loss value: 8.619743\n",
      "Filter 69 processed in 14s\n",
      "Processing filter 70\n",
      "Current loss value: 0.1756265\n",
      "Current loss value: 0.67759365\n",
      "Current loss value: 1.2385583\n",
      "Current loss value: 1.542302\n",
      "Current loss value: 2.2431505\n",
      "Current loss value: 2.6143837\n",
      "Current loss value: 2.9495769\n",
      "Current loss value: 3.4285865\n",
      "Current loss value: 3.7407155\n",
      "Current loss value: 4.051593\n",
      "Current loss value: 4.2629995\n",
      "Current loss value: 4.5055447\n",
      "Current loss value: 5.188204\n",
      "Current loss value: 5.534005\n",
      "Current loss value: 5.9050055\n",
      "Current loss value: 5.9603515\n",
      "Current loss value: 6.0844975\n",
      "Current loss value: 6.512231\n",
      "Current loss value: 6.834834\n",
      "Current loss value: 6.825143\n",
      "Filter 70 processed in 14s\n",
      "Processing filter 71\n",
      "Current loss value: 0.8339193\n",
      "Current loss value: 2.2208395\n",
      "Current loss value: 2.973213\n",
      "Current loss value: 4.2792683\n",
      "Current loss value: 5.348435\n",
      "Current loss value: 6.2024927\n",
      "Current loss value: 6.843984\n",
      "Current loss value: 7.3274593\n",
      "Current loss value: 8.0803795\n",
      "Current loss value: 8.482907\n",
      "Current loss value: 9.196277\n",
      "Current loss value: 9.809847\n",
      "Current loss value: 9.715366\n",
      "Current loss value: 10.691777\n",
      "Current loss value: 10.833242\n",
      "Current loss value: 11.181698\n",
      "Current loss value: 11.819181\n",
      "Current loss value: 12.325097\n",
      "Current loss value: 12.366291\n",
      "Current loss value: 12.8516035\n",
      "Filter 71 processed in 14s\n",
      "Processing filter 72\n",
      "Current loss value: -0.9233727\n",
      "Filter 72 processed in 12s\n",
      "Processing filter 73\n",
      "Current loss value: -0.09722623\n",
      "Filter 73 processed in 12s\n",
      "Processing filter 74\n",
      "Current loss value: -0.59387296\n",
      "Filter 74 processed in 13s\n",
      "Processing filter 75\n",
      "Current loss value: -0.34617272\n",
      "Filter 75 processed in 13s\n",
      "Processing filter 76\n",
      "Current loss value: -0.10422548\n",
      "Filter 76 processed in 13s\n",
      "Processing filter 77\n",
      "Current loss value: 0.7194723\n",
      "Current loss value: 0.8363978\n",
      "Current loss value: 1.5503266\n",
      "Current loss value: 2.0231447\n",
      "Current loss value: 2.5769048\n",
      "Current loss value: 3.1720786\n",
      "Current loss value: 3.7861266\n",
      "Current loss value: 3.9579837\n",
      "Current loss value: 4.2143416\n",
      "Current loss value: 5.1801243\n",
      "Current loss value: 5.3326683\n",
      "Current loss value: 5.868922\n",
      "Current loss value: 5.7170477\n",
      "Current loss value: 6.865539\n",
      "Current loss value: 6.78501\n",
      "Current loss value: 6.6962724\n",
      "Current loss value: 7.267574\n",
      "Current loss value: 7.191396\n",
      "Current loss value: 7.876475\n",
      "Current loss value: 8.0071945\n",
      "Filter 77 processed in 15s\n",
      "Processing filter 78\n",
      "Current loss value: -1.9169824\n",
      "Filter 78 processed in 13s\n",
      "Processing filter 79\n",
      "Current loss value: -1.742419\n",
      "Filter 79 processed in 13s\n",
      "Processing filter 80\n",
      "Current loss value: -1.1391051\n",
      "Filter 80 processed in 14s\n",
      "Processing filter 81\n",
      "Current loss value: -1.0085856\n",
      "Filter 81 processed in 14s\n",
      "Processing filter 82\n",
      "Current loss value: -1.2769853\n",
      "Filter 82 processed in 14s\n",
      "Processing filter 83\n",
      "Current loss value: -0.6387153\n",
      "Filter 83 processed in 16s\n",
      "Processing filter 84\n",
      "Current loss value: -0.7982646\n",
      "Filter 84 processed in 15s\n",
      "Processing filter 85\n",
      "Current loss value: -0.43798095\n",
      "Filter 85 processed in 15s\n",
      "Processing filter 86\n",
      "Current loss value: -1.4613074\n",
      "Filter 86 processed in 15s\n",
      "Processing filter 87\n",
      "Current loss value: -1.2315512\n",
      "Filter 87 processed in 15s\n",
      "Processing filter 88\n",
      "Current loss value: -0.7657343\n",
      "Filter 88 processed in 15s\n",
      "Processing filter 89\n",
      "Current loss value: -1.9819866\n",
      "Filter 89 processed in 15s\n",
      "Processing filter 90\n",
      "Current loss value: -0.9016482\n",
      "Filter 90 processed in 16s\n",
      "Processing filter 91\n",
      "Current loss value: 0.21388346\n",
      "Current loss value: 1.312376\n",
      "Current loss value: 2.4055943\n",
      "Current loss value: 3.0278535\n",
      "Current loss value: 4.196682\n",
      "Current loss value: 4.886586\n",
      "Current loss value: 5.9615617\n",
      "Current loss value: 6.3343196\n",
      "Current loss value: 7.2191176\n",
      "Current loss value: 7.509167\n",
      "Current loss value: 8.124246\n",
      "Current loss value: 8.50338\n",
      "Current loss value: 9.028384\n",
      "Current loss value: 9.276685\n",
      "Current loss value: 10.256417\n",
      "Current loss value: 10.554174\n",
      "Current loss value: 10.897127\n",
      "Current loss value: 11.163704\n",
      "Current loss value: 11.636487\n",
      "Current loss value: 12.125247\n",
      "Filter 91 processed in 18s\n",
      "Processing filter 92\n",
      "Current loss value: 0.26452264\n",
      "Current loss value: 0.7424469\n",
      "Current loss value: 1.322364\n",
      "Current loss value: 1.8834438\n",
      "Current loss value: 2.1002328\n",
      "Current loss value: 2.6682682\n",
      "Current loss value: 2.9398813\n",
      "Current loss value: 3.2545981\n",
      "Current loss value: 3.7785428\n",
      "Current loss value: 4.243195\n",
      "Current loss value: 4.6151757\n",
      "Current loss value: 4.8380938\n",
      "Current loss value: 4.9607196\n",
      "Current loss value: 5.535651\n",
      "Current loss value: 5.987879\n",
      "Current loss value: 6.1538353\n",
      "Current loss value: 6.5097847\n",
      "Current loss value: 6.7889037\n",
      "Current loss value: 7.268241\n",
      "Current loss value: 7.5673814\n",
      "Filter 92 processed in 18s\n",
      "Processing filter 93\n",
      "Current loss value: 0.34566638\n",
      "Current loss value: 0.45755798\n",
      "Current loss value: 1.2449604\n",
      "Current loss value: 2.2305126\n",
      "Current loss value: 2.8854642\n",
      "Current loss value: 3.1992717\n",
      "Current loss value: 4.1365905\n",
      "Current loss value: 4.17922\n",
      "Current loss value: 4.877871\n",
      "Current loss value: 5.5238013\n",
      "Current loss value: 6.0470963\n",
      "Current loss value: 6.46735\n",
      "Current loss value: 6.7451887\n",
      "Current loss value: 7.6055627\n",
      "Current loss value: 7.612087\n",
      "Current loss value: 8.317877\n",
      "Current loss value: 8.415959\n",
      "Current loss value: 8.788321\n",
      "Current loss value: 9.437876\n",
      "Current loss value: 9.689325\n",
      "Filter 93 processed in 18s\n",
      "Processing filter 94\n",
      "Current loss value: 0.029228035\n",
      "Current loss value: 0.8261892\n",
      "Current loss value: 1.9209293\n",
      "Current loss value: 2.9082766\n",
      "Current loss value: 3.3321898\n",
      "Current loss value: 3.7086225\n",
      "Current loss value: 4.098404\n",
      "Current loss value: 4.835462\n",
      "Current loss value: 5.2717047\n",
      "Current loss value: 5.855845\n",
      "Current loss value: 6.0883684\n",
      "Current loss value: 6.57217\n",
      "Current loss value: 6.874722\n",
      "Current loss value: 7.5995436\n",
      "Current loss value: 7.77384\n",
      "Current loss value: 8.102562\n",
      "Current loss value: 8.275204\n",
      "Current loss value: 8.6534395\n",
      "Current loss value: 8.8691435\n",
      "Current loss value: 9.237123\n",
      "Filter 94 processed in 19s\n",
      "Processing filter 95\n",
      "Current loss value: -0.2001161\n",
      "Filter 95 processed in 17s\n",
      "Processing filter 96\n",
      "Current loss value: -1.125117\n",
      "Filter 96 processed in 17s\n",
      "Processing filter 97\n",
      "Current loss value: -2.0050247\n",
      "Filter 97 processed in 18s\n",
      "Processing filter 98\n",
      "Current loss value: -0.53776026\n",
      "Filter 98 processed in 18s\n",
      "Processing filter 99\n",
      "Current loss value: -1.254327\n",
      "Filter 99 processed in 18s\n",
      "Processing filter 100\n",
      "Current loss value: -1.5145532\n",
      "Filter 100 processed in 18s\n",
      "Processing filter 101\n",
      "Current loss value: -1.9914367\n",
      "Filter 101 processed in 19s\n",
      "Processing filter 102\n",
      "Current loss value: -0.8337166\n",
      "Filter 102 processed in 19s\n",
      "Processing filter 103\n",
      "Current loss value: 0.05117497\n",
      "Current loss value: 0.8580276\n",
      "Current loss value: 1.9760361\n",
      "Current loss value: 3.0564563\n",
      "Current loss value: 3.8548636\n",
      "Current loss value: 4.610186\n",
      "Current loss value: 4.8667955\n",
      "Current loss value: 5.6478367\n",
      "Current loss value: 6.044766\n",
      "Current loss value: 6.5865097\n",
      "Current loss value: 7.1514645\n",
      "Current loss value: 7.77263\n",
      "Current loss value: 8.253394\n",
      "Current loss value: 8.531509\n",
      "Current loss value: 9.08807\n",
      "Current loss value: 9.473168\n",
      "Current loss value: 9.60596\n",
      "Current loss value: 10.268182\n",
      "Current loss value: 10.485045\n",
      "Current loss value: 10.961077\n",
      "Filter 103 processed in 21s\n",
      "Processing filter 104\n",
      "Current loss value: -1.9451263\n",
      "Filter 104 processed in 19s\n",
      "Processing filter 105\n",
      "Current loss value: -1.5927379\n",
      "Filter 105 processed in 20s\n",
      "Processing filter 106\n",
      "Current loss value: -1.2571318\n",
      "Filter 106 processed in 21s\n",
      "Processing filter 107\n",
      "Current loss value: -0.6359623\n",
      "Filter 107 processed in 20s\n",
      "Processing filter 108\n",
      "Current loss value: -0.26327023\n",
      "Filter 108 processed in 20s\n",
      "Processing filter 109\n",
      "Current loss value: 0.079844415\n",
      "Current loss value: 0.8521988\n",
      "Current loss value: 1.5719585\n",
      "Current loss value: 1.9392892\n",
      "Current loss value: 2.4732723\n",
      "Current loss value: 3.2589567\n",
      "Current loss value: 3.8809092\n",
      "Current loss value: 4.2690578\n",
      "Current loss value: 4.940557\n",
      "Current loss value: 5.2372155\n",
      "Current loss value: 5.8158684\n",
      "Current loss value: 6.228107\n",
      "Current loss value: 6.3898005\n",
      "Current loss value: 6.820854\n",
      "Current loss value: 7.057662\n",
      "Current loss value: 7.3758883\n",
      "Current loss value: 7.618357\n",
      "Current loss value: 8.133265\n",
      "Current loss value: 8.150594\n",
      "Current loss value: 8.725908\n",
      "Filter 109 processed in 23s\n",
      "Processing filter 110\n",
      "Current loss value: 1.7195786\n",
      "Current loss value: 2.848925\n",
      "Current loss value: 4.6837683\n",
      "Current loss value: 6.423211\n",
      "Current loss value: 8.116959\n",
      "Current loss value: 8.81856\n",
      "Current loss value: 10.214241\n",
      "Current loss value: 11.246037\n",
      "Current loss value: 11.856963\n",
      "Current loss value: 13.117968\n",
      "Current loss value: 13.685187\n",
      "Current loss value: 14.598503\n",
      "Current loss value: 15.0792885\n",
      "Current loss value: 16.313076\n",
      "Current loss value: 17.09559\n",
      "Current loss value: 17.296108\n",
      "Current loss value: 17.656343\n",
      "Current loss value: 19.222998\n",
      "Current loss value: 19.573534\n",
      "Current loss value: 20.574879\n",
      "Filter 110 processed in 23s\n",
      "Processing filter 111\n",
      "Current loss value: 0.37647933\n",
      "Current loss value: 0.8637166\n",
      "Current loss value: 1.5422955\n",
      "Current loss value: 2.077488\n",
      "Current loss value: 2.5284026\n",
      "Current loss value: 3.1989098\n",
      "Current loss value: 3.8486755\n",
      "Current loss value: 4.001906\n",
      "Current loss value: 4.400613\n",
      "Current loss value: 4.842703\n",
      "Current loss value: 4.7201276\n",
      "Current loss value: 5.626249\n",
      "Current loss value: 5.5886145\n",
      "Current loss value: 6.070294\n",
      "Current loss value: 5.728913\n",
      "Current loss value: 6.577221\n",
      "Current loss value: 6.719468\n",
      "Current loss value: 6.8196397\n",
      "Current loss value: 7.273535\n",
      "Current loss value: 7.3821287\n",
      "Filter 111 processed in 22s\n",
      "Processing filter 112\n",
      "Current loss value: -1.5116396\n",
      "Filter 112 processed in 21s\n",
      "Processing filter 113\n",
      "Current loss value: -2.2865984\n",
      "Filter 113 processed in 21s\n",
      "Processing filter 114\n",
      "Current loss value: -0.041493002\n",
      "Filter 114 processed in 22s\n",
      "Processing filter 115\n",
      "Current loss value: 0.8807834\n",
      "Current loss value: 1.8707579\n",
      "Current loss value: 2.5041094\n",
      "Current loss value: 3.1206298\n",
      "Current loss value: 3.3406677\n",
      "Current loss value: 3.856376\n",
      "Current loss value: 4.165272\n",
      "Current loss value: 5.062709\n",
      "Current loss value: 5.446773\n",
      "Current loss value: 5.952378\n",
      "Current loss value: 6.3899612\n",
      "Current loss value: 7.0630956\n",
      "Current loss value: 7.2513757\n",
      "Current loss value: 7.606582\n",
      "Current loss value: 7.9714785\n",
      "Current loss value: 8.374368\n",
      "Current loss value: 8.352156\n",
      "Current loss value: 9.007451\n",
      "Current loss value: 9.491617\n",
      "Current loss value: 9.796971\n",
      "Filter 115 processed in 24s\n",
      "Processing filter 116\n",
      "Current loss value: -0.54057264\n",
      "Filter 116 processed in 22s\n",
      "Processing filter 117\n",
      "Current loss value: -0.4322069\n",
      "Filter 117 processed in 23s\n",
      "Processing filter 118\n",
      "Current loss value: -1.3756235\n",
      "Filter 118 processed in 23s\n",
      "Processing filter 119\n",
      "Current loss value: -1.1815654\n",
      "Filter 119 processed in 23s\n",
      "Processing filter 120\n",
      "Current loss value: -1.5191544\n",
      "Filter 120 processed in 24s\n",
      "Processing filter 121\n",
      "Current loss value: -0.64710337\n",
      "Filter 121 processed in 24s\n",
      "Processing filter 122\n",
      "Current loss value: 0.8443481\n",
      "Current loss value: 1.1864531\n",
      "Current loss value: 2.06014\n",
      "Current loss value: 2.8310862\n",
      "Current loss value: 3.734294\n",
      "Current loss value: 4.527728\n",
      "Current loss value: 4.949044\n",
      "Current loss value: 5.676678\n",
      "Current loss value: 5.786361\n",
      "Current loss value: 6.3225946\n",
      "Current loss value: 6.578921\n",
      "Current loss value: 6.9484925\n",
      "Current loss value: 7.193974\n",
      "Current loss value: 7.2615128\n",
      "Current loss value: 7.829559\n",
      "Current loss value: 7.761534\n",
      "Current loss value: 8.367025\n",
      "Current loss value: 8.341243\n",
      "Current loss value: 8.619137\n",
      "Current loss value: 8.829527\n",
      "Filter 122 processed in 26s\n",
      "Processing filter 123\n",
      "Current loss value: -1.3404286\n",
      "Filter 123 processed in 24s\n",
      "Processing filter 124\n",
      "Current loss value: -1.3151916\n",
      "Filter 124 processed in 24s\n",
      "Processing filter 125\n",
      "Current loss value: -2.7349896\n",
      "Filter 125 processed in 25s\n",
      "Processing filter 126\n",
      "Current loss value: -1.6670803\n",
      "Filter 126 processed in 25s\n",
      "Processing filter 127\n",
      "Current loss value: -0.61970615\n",
      "Filter 127 processed in 26s\n",
      "Processing filter 128\n",
      "Current loss value: -0.60844415\n",
      "Filter 128 processed in 25s\n",
      "Processing filter 129\n",
      "Current loss value: -0.86755514\n",
      "Filter 129 processed in 26s\n",
      "Processing filter 130\n",
      "Current loss value: -0.7262855\n",
      "Filter 130 processed in 26s\n",
      "Processing filter 131\n",
      "Current loss value: -2.3741856\n",
      "Filter 131 processed in 26s\n",
      "Processing filter 132\n",
      "Current loss value: -1.2591243\n",
      "Filter 132 processed in 27s\n",
      "Processing filter 133\n",
      "Current loss value: -1.5559765\n",
      "Filter 133 processed in 28s\n",
      "Processing filter 134\n",
      "Current loss value: -1.0613855\n",
      "Filter 134 processed in 29s\n",
      "Processing filter 135\n",
      "Current loss value: -1.1737766\n",
      "Filter 135 processed in 28s\n",
      "Processing filter 136\n",
      "Current loss value: -0.13831732\n",
      "Filter 136 processed in 28s\n",
      "Processing filter 137\n",
      "Current loss value: 0.41826388\n",
      "Current loss value: 2.054661\n",
      "Current loss value: 3.3647301\n",
      "Current loss value: 4.4357114\n",
      "Current loss value: 5.023311\n",
      "Current loss value: 5.6041236\n",
      "Current loss value: 6.178644\n",
      "Current loss value: 6.489457\n",
      "Current loss value: 7.0824313\n",
      "Current loss value: 7.4298058\n",
      "Current loss value: 7.7166843\n",
      "Current loss value: 8.37076\n",
      "Current loss value: 8.567908\n",
      "Current loss value: 8.909209\n",
      "Current loss value: 9.464802\n",
      "Current loss value: 9.531515\n",
      "Current loss value: 9.819026\n",
      "Current loss value: 10.277151\n",
      "Current loss value: 10.189658\n",
      "Current loss value: 10.556855\n",
      "Filter 137 processed in 30s\n",
      "Processing filter 138\n",
      "Current loss value: 0.530922\n",
      "Current loss value: 1.6310683\n",
      "Current loss value: 2.4173546\n",
      "Current loss value: 3.8695285\n",
      "Current loss value: 4.931737\n",
      "Current loss value: 5.7504435\n",
      "Current loss value: 6.540463\n",
      "Current loss value: 6.976609\n",
      "Current loss value: 7.39346\n",
      "Current loss value: 7.6058784\n",
      "Current loss value: 8.116926\n",
      "Current loss value: 8.746742\n",
      "Current loss value: 8.74967\n",
      "Current loss value: 9.340473\n",
      "Current loss value: 9.484171\n",
      "Current loss value: 9.758683\n",
      "Current loss value: 10.130675\n",
      "Current loss value: 10.284699\n",
      "Current loss value: 10.713741\n",
      "Current loss value: 10.888635\n",
      "Filter 138 processed in 31s\n",
      "Processing filter 139\n",
      "Current loss value: -1.2262254\n",
      "Filter 139 processed in 29s\n",
      "Processing filter 140\n",
      "Current loss value: -1.1575446\n",
      "Filter 140 processed in 30s\n",
      "Processing filter 141\n",
      "Current loss value: -1.3263041\n",
      "Filter 141 processed in 30s\n",
      "Processing filter 142\n",
      "Current loss value: 0.44697198\n",
      "Current loss value: 0.96849495\n",
      "Current loss value: 1.5387545\n",
      "Current loss value: 2.1195736\n",
      "Current loss value: 2.8055809\n",
      "Current loss value: 3.111896\n",
      "Current loss value: 3.5393677\n",
      "Current loss value: 3.8246968\n",
      "Current loss value: 4.3074145\n",
      "Current loss value: 4.9572625\n",
      "Current loss value: 5.3677855\n",
      "Current loss value: 5.743283\n",
      "Current loss value: 6.1687274\n",
      "Current loss value: 6.58303\n",
      "Current loss value: 7.015115\n",
      "Current loss value: 7.3657923\n",
      "Current loss value: 8.011966\n",
      "Current loss value: 7.969272\n",
      "Current loss value: 8.523961\n",
      "Current loss value: 8.557463\n",
      "Filter 142 processed in 33s\n",
      "Processing filter 143\n",
      "Current loss value: -1.1539456\n",
      "Filter 143 processed in 31s\n",
      "Processing filter 144\n",
      "Current loss value: -1.4632307\n",
      "Filter 144 processed in 31s\n",
      "Processing filter 145\n",
      "Current loss value: -1.4286846\n",
      "Filter 145 processed in 31s\n",
      "Processing filter 146\n",
      "Current loss value: -1.9250042\n",
      "Filter 146 processed in 32s\n",
      "Processing filter 147\n",
      "Current loss value: -1.4741733\n",
      "Filter 147 processed in 32s\n",
      "Processing filter 148\n",
      "Current loss value: 0.44673702\n",
      "Current loss value: 1.2266033\n",
      "Current loss value: 1.9482895\n",
      "Current loss value: 2.169502\n",
      "Current loss value: 3.1079445\n",
      "Current loss value: 3.7006073\n",
      "Current loss value: 3.9766066\n",
      "Current loss value: 4.071321\n",
      "Current loss value: 4.5420284\n",
      "Current loss value: 4.9067526\n",
      "Current loss value: 5.0613875\n",
      "Current loss value: 5.3156476\n",
      "Current loss value: 6.165588\n",
      "Current loss value: 6.2924743\n",
      "Current loss value: 6.450696\n",
      "Current loss value: 6.9100103\n",
      "Current loss value: 7.2302027\n",
      "Current loss value: 7.445315\n",
      "Current loss value: 7.728715\n",
      "Current loss value: 7.653766\n",
      "Filter 148 processed in 35s\n",
      "Processing filter 149\n",
      "Current loss value: -0.47471327\n",
      "Filter 149 processed in 33s\n",
      "Processing filter 150\n",
      "Current loss value: -0.17302254\n",
      "Filter 150 processed in 33s\n",
      "Processing filter 151\n",
      "Current loss value: -0.69519585\n",
      "Filter 151 processed in 33s\n",
      "Processing filter 152\n",
      "Current loss value: -0.397458\n",
      "Filter 152 processed in 34s\n",
      "Processing filter 153\n",
      "Current loss value: -0.39044163\n",
      "Filter 153 processed in 33s\n",
      "Processing filter 154\n",
      "Current loss value: -1.2724234\n",
      "Filter 154 processed in 34s\n",
      "Processing filter 155\n",
      "Current loss value: -0.5888185\n",
      "Filter 155 processed in 34s\n",
      "Processing filter 156\n",
      "Current loss value: -0.43414956\n",
      "Filter 156 processed in 35s\n",
      "Processing filter 157\n",
      "Current loss value: -0.5356415\n",
      "Filter 157 processed in 35s\n",
      "Processing filter 158\n",
      "Current loss value: -1.2076573\n",
      "Filter 158 processed in 35s\n",
      "Processing filter 159\n",
      "Current loss value: -2.1387901\n",
      "Filter 159 processed in 36s\n",
      "Processing filter 160\n",
      "Current loss value: -1.6948867\n",
      "Filter 160 processed in 36s\n",
      "Processing filter 161\n",
      "Current loss value: -1.4586409\n",
      "Filter 161 processed in 36s\n",
      "Processing filter 162\n",
      "Current loss value: -0.6184504\n",
      "Filter 162 processed in 36s\n",
      "Processing filter 163\n",
      "Current loss value: -0.54055405\n",
      "Filter 163 processed in 37s\n",
      "Processing filter 164\n",
      "Current loss value: -0.27259925\n",
      "Filter 164 processed in 38s\n",
      "Processing filter 165\n",
      "Current loss value: -1.0470586\n",
      "Filter 165 processed in 38s\n",
      "Processing filter 166\n",
      "Current loss value: -0.25066367\n",
      "Filter 166 processed in 39s\n",
      "Processing filter 167\n",
      "Current loss value: -0.41330606\n",
      "Filter 167 processed in 39s\n",
      "Processing filter 168\n",
      "Current loss value: -1.8975457\n",
      "Filter 168 processed in 41s\n",
      "Processing filter 169\n",
      "Current loss value: -0.55794275\n",
      "Filter 169 processed in 40s\n",
      "Processing filter 170\n",
      "Current loss value: -0.021022718\n",
      "Filter 170 processed in 40s\n",
      "Processing filter 171\n",
      "Current loss value: -0.37784776\n",
      "Filter 171 processed in 41s\n",
      "Processing filter 172\n",
      "Current loss value: -0.13085972\n",
      "Filter 172 processed in 41s\n",
      "Processing filter 173\n",
      "Current loss value: -1.1580172\n",
      "Filter 173 processed in 41s\n",
      "Processing filter 174\n",
      "Current loss value: -1.5883646\n",
      "Filter 174 processed in 42s\n",
      "Processing filter 175\n",
      "Current loss value: 0.24018562\n",
      "Current loss value: 1.8087137\n",
      "Current loss value: 3.458657\n",
      "Current loss value: 5.6382074\n",
      "Current loss value: 6.794342\n",
      "Current loss value: 7.3239994\n",
      "Current loss value: 7.8734455\n",
      "Current loss value: 8.963041\n",
      "Current loss value: 9.738964\n",
      "Current loss value: 10.1473055\n",
      "Current loss value: 11.063687\n",
      "Current loss value: 11.501437\n",
      "Current loss value: 12.470267\n",
      "Current loss value: 12.527977\n",
      "Current loss value: 13.282294\n",
      "Current loss value: 13.394602\n",
      "Current loss value: 14.042032\n",
      "Current loss value: 13.939456\n",
      "Current loss value: 14.687596\n",
      "Current loss value: 14.704684\n",
      "Filter 175 processed in 44s\n",
      "Processing filter 176\n",
      "Current loss value: 0.056128744\n",
      "Current loss value: 0.5147984\n",
      "Current loss value: 1.0978637\n",
      "Current loss value: 1.8419958\n",
      "Current loss value: 2.3475544\n",
      "Current loss value: 2.676705\n",
      "Current loss value: 3.3591247\n",
      "Current loss value: 3.490305\n",
      "Current loss value: 3.7818851\n",
      "Current loss value: 4.290553\n",
      "Current loss value: 4.5092483\n",
      "Current loss value: 5.195478\n",
      "Current loss value: 5.3615766\n",
      "Current loss value: 5.6860714\n",
      "Current loss value: 6.076572\n",
      "Current loss value: 6.349389\n",
      "Current loss value: 6.680983\n",
      "Current loss value: 6.6790423\n",
      "Current loss value: 7.1655397\n",
      "Current loss value: 7.526497\n",
      "Filter 176 processed in 44s\n",
      "Processing filter 177\n",
      "Current loss value: -1.0104198\n",
      "Filter 177 processed in 42s\n",
      "Processing filter 178\n",
      "Current loss value: -0.48771256\n",
      "Filter 178 processed in 42s\n",
      "Processing filter 179\n",
      "Current loss value: -2.9901142\n",
      "Filter 179 processed in 43s\n",
      "Processing filter 180\n",
      "Current loss value: 0.048995007\n",
      "Current loss value: 1.0877072\n",
      "Current loss value: 2.1184013\n",
      "Current loss value: 3.2276876\n",
      "Current loss value: 4.371435\n",
      "Current loss value: 5.0968256\n",
      "Current loss value: 5.894845\n",
      "Current loss value: 6.567255\n",
      "Current loss value: 7.103227\n",
      "Current loss value: 7.6691036\n",
      "Current loss value: 7.9607034\n",
      "Current loss value: 8.582899\n",
      "Current loss value: 8.853927\n",
      "Current loss value: 9.118289\n",
      "Current loss value: 9.534388\n",
      "Current loss value: 9.820836\n",
      "Current loss value: 10.300324\n",
      "Current loss value: 10.60376\n",
      "Current loss value: 11.027013\n",
      "Current loss value: 11.118376\n",
      "Filter 180 processed in 45s\n",
      "Processing filter 181\n",
      "Current loss value: -1.2511933\n",
      "Filter 181 processed in 44s\n",
      "Processing filter 182\n",
      "Current loss value: 0.0064233565\n",
      "Current loss value: 0.31516162\n",
      "Current loss value: 0.83302176\n",
      "Current loss value: 0.9855983\n",
      "Current loss value: 1.2851886\n",
      "Current loss value: 1.6194718\n",
      "Current loss value: 1.6449429\n",
      "Current loss value: 1.9957138\n",
      "Current loss value: 2.166054\n",
      "Current loss value: 2.6392672\n",
      "Current loss value: 2.9010072\n",
      "Current loss value: 3.1290526\n",
      "Current loss value: 3.4803119\n",
      "Current loss value: 3.9884295\n",
      "Current loss value: 4.221297\n",
      "Current loss value: 4.3284054\n",
      "Current loss value: 4.9140434\n",
      "Current loss value: 4.5087566\n",
      "Current loss value: 5.6298056\n",
      "Current loss value: 5.435087\n",
      "Filter 182 processed in 45s\n",
      "Processing filter 183\n",
      "Current loss value: 0.64336723\n",
      "Current loss value: 1.9139991\n",
      "Current loss value: 3.5849378\n",
      "Current loss value: 5.2564206\n",
      "Current loss value: 6.7921004\n",
      "Current loss value: 8.05275\n",
      "Current loss value: 8.767514\n",
      "Current loss value: 9.861908\n",
      "Current loss value: 10.735436\n",
      "Current loss value: 11.476287\n",
      "Current loss value: 12.307006\n",
      "Current loss value: 12.647279\n",
      "Current loss value: 13.284656\n",
      "Current loss value: 13.867318\n",
      "Current loss value: 14.374887\n",
      "Current loss value: 14.720798\n",
      "Current loss value: 15.055973\n",
      "Current loss value: 15.71599\n",
      "Current loss value: 15.729704\n",
      "Current loss value: 16.40785\n",
      "Filter 183 processed in 46s\n",
      "Processing filter 184\n",
      "Current loss value: -1.1560969\n",
      "Filter 184 processed in 45s\n",
      "Processing filter 185\n",
      "Current loss value: -0.86419135\n",
      "Filter 185 processed in 46s\n",
      "Processing filter 186\n",
      "Current loss value: -1.2402921\n",
      "Filter 186 processed in 46s\n",
      "Processing filter 187\n",
      "Current loss value: -1.6699834\n",
      "Filter 187 processed in 46s\n",
      "Processing filter 188\n",
      "Current loss value: -1.4783385\n",
      "Filter 188 processed in 47s\n",
      "Processing filter 189\n",
      "Current loss value: -0.28414953\n",
      "Filter 189 processed in 47s\n",
      "Processing filter 190\n",
      "Current loss value: -1.5979096\n",
      "Filter 190 processed in 47s\n",
      "Processing filter 191\n",
      "Current loss value: -0.8008759\n",
      "Filter 191 processed in 48s\n",
      "Processing filter 192\n",
      "Current loss value: -0.37858835\n",
      "Filter 192 processed in 48s\n",
      "Processing filter 193\n",
      "Current loss value: -2.3283324\n",
      "Filter 193 processed in 48s\n",
      "Processing filter 194\n",
      "Current loss value: -0.4396732\n",
      "Filter 194 processed in 49s\n",
      "Processing filter 195\n",
      "Current loss value: -1.5842378\n",
      "Filter 195 processed in 49s\n",
      "Processing filter 196\n",
      "Current loss value: -0.76934814\n",
      "Filter 196 processed in 50s\n",
      "Processing filter 197\n",
      "Current loss value: -0.374903\n",
      "Filter 197 processed in 51s\n",
      "Processing filter 198\n",
      "Current loss value: -0.3473789\n",
      "Filter 198 processed in 51s\n",
      "Processing filter 199\n",
      "Current loss value: -0.14574546\n",
      "Filter 199 processed in 51s\n"
     ]
    }
   ],
   "source": [
    "kept_filters = []\n",
    "for filter_index in range(200):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 5\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print(i,j)\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        width_margin = (img_width + margin) * i\n",
    "        height_margin = (img_height + margin) * j\n",
    "        stitched_filters[\n",
    "            width_margin: width_margin + img_width,\n",
    "            height_margin: height_margin + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "save_img('stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m             \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m             \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m             \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m             \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Instantiates the ResNet50 architecture.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Optionally loads weights pre-trained on ImageNet.\u001b[0m\n",
       "\u001b[0;34m    Note that the data format convention used by the model is\u001b[0m\n",
       "\u001b[0;34m    the one specified in your Keras config at `~/.keras/keras.json`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    # Arguments\u001b[0m\n",
       "\u001b[0;34m        include_top: whether to include the fully-connected\u001b[0m\n",
       "\u001b[0;34m            layer at the top of the network.\u001b[0m\n",
       "\u001b[0;34m        weights: one of `None` (random initialization),\u001b[0m\n",
       "\u001b[0;34m              'imagenet' (pre-training on ImageNet),\u001b[0m\n",
       "\u001b[0;34m              or the path to the weights file to be loaded.\u001b[0m\n",
       "\u001b[0;34m        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\u001b[0m\n",
       "\u001b[0;34m            to use as image input for the model.\u001b[0m\n",
       "\u001b[0;34m        input_shape: optional shape tuple, only to be specified\u001b[0m\n",
       "\u001b[0;34m            if `include_top` is False (otherwise the input shape\u001b[0m\n",
       "\u001b[0;34m            has to be `(224, 224, 3)` (with `channels_last` data format)\u001b[0m\n",
       "\u001b[0;34m            or `(3, 224, 224)` (with `channels_first` data format).\u001b[0m\n",
       "\u001b[0;34m            It should have exactly 3 inputs channels,\u001b[0m\n",
       "\u001b[0;34m            and width and height should be no smaller than 197.\u001b[0m\n",
       "\u001b[0;34m            E.g. `(200, 200, 3)` would be one valid value.\u001b[0m\n",
       "\u001b[0;34m        pooling: Optional pooling mode for feature extraction\u001b[0m\n",
       "\u001b[0;34m            when `include_top` is `False`.\u001b[0m\n",
       "\u001b[0;34m            - `None` means that the output of the model will be\u001b[0m\n",
       "\u001b[0;34m                the 4D tensor output of the\u001b[0m\n",
       "\u001b[0;34m                last convolutional layer.\u001b[0m\n",
       "\u001b[0;34m            - `avg` means that global average pooling\u001b[0m\n",
       "\u001b[0;34m                will be applied to the output of the\u001b[0m\n",
       "\u001b[0;34m                last convolutional layer, and thus\u001b[0m\n",
       "\u001b[0;34m                the output of the model will be a 2D tensor.\u001b[0m\n",
       "\u001b[0;34m            - `max` means that global max pooling will\u001b[0m\n",
       "\u001b[0;34m                be applied.\u001b[0m\n",
       "\u001b[0;34m        classes: optional number of classes to classify images\u001b[0m\n",
       "\u001b[0;34m            into, only to be specified if `include_top` is True, and\u001b[0m\n",
       "\u001b[0;34m            if no `weights` argument is specified.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    # Returns\u001b[0m\n",
       "\u001b[0;34m        A Keras model instance.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    # Raises\u001b[0m\n",
       "\u001b[0;34m        ValueError: in case of invalid argument for `weights`,\u001b[0m\n",
       "\u001b[0;34m            or invalid input shape.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The `weights` argument should be either '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                         \u001b[0;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                         \u001b[0;34m'(pre-training on ImageNet), '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                         \u001b[0;34m'or the path to the weights file to be loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minclude_top\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'If using `weights` as `\"imagenet\"` with `include_top`'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                         \u001b[0;34m' as true, `classes` should be 1000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Determine proper input shape\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_obtain_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m197\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbn_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbn_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1_pad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbn_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bn_conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc1000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The output shape of `ResNet50(include_top=False)` '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                          \u001b[0;34m'has been changed since Keras 2.2.0.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Ensure that the model takes into account\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# any potential predecessors of `input_tensor`.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_source_inputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mget_source_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mget_source_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_input\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Create model.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Load weights.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m'resnet50_weights_tf_dim_ordering_tf_kernels.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mWEIGHTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmd5_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a7b3fe01876f51b976af0dea6bc144eb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mWEIGHTS_PATH_NO_TOP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmd5_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a268eb855778b3df3c7506639542a6af'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkeras_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda/envs/py35/lib/python3.5/site-packages/keras_applications/resnet50.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??applications.ResNet50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
